{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Exploration and Preprocessing"
      ],
      "metadata": {
        "id": "-VJJwo_zIE31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A. Load Data and basic exploration**"
      ],
      "metadata": {
        "id": "tL7YAtiDIVrn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f4rV8ymiHjrw",
        "outputId": "8829f7ab-0bcb-4622-94ce-aa387b907ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "\n",
        "df = pd.read_csv(\"/content/Imdb - data_imdb.csv\")\n",
        "\n",
        "# ccheck shape and first rows\n",
        "\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_xqcJOcmJweR",
        "outputId": "61e601c9-cc69-44f1-d444-dd8355867200"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n",
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHecking for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "#check class balance\n",
        "print(df['sentiment'].value_counts())\n",
        "\n",
        "#check review lengths\n",
        "df['review_length'] = df['review'].apply(len)\n",
        "df['review_length'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "IsJsk5INbarH",
        "outputId": "15a44bce-f6f6-4c36-cf00-926ffad661dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review       0\n",
            "sentiment    0\n",
            "dtype: int64\n",
            "sentiment\n",
            "positive    25000\n",
            "negative    25000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    50000.000000\n",
              "mean      1309.367720\n",
              "std        989.759532\n",
              "min          7.000000\n",
              "25%        699.000000\n",
              "50%        970.000000\n",
              "75%       1590.000000\n",
              "max      13704.000000\n",
              "Name: review_length, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>50000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1309.367720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>989.759532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>699.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>970.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1590.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>13704.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Data Cleaning and Text Preprocessing**\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "*    Lowercasing\n",
        "*    Remove punctutation,numbers,and special characters\n",
        "*    Remove stop words\n",
        "*    Tokenization\n",
        "*    Lemmatization\n"
      ],
      "metadata": {
        "id": "uF2XAJ3ncz9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "7IED6Oklcyo2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text (text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^a-z\\s]',\"\",text)\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "#apply clean text on df\n",
        "\n",
        "df['clean_review'] = df['review'].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "rhipBlpXdfzz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Feature Engineering**"
      ],
      "metadata": {
        "id": "DLVmpXalePmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforming text into vectors using TF-IDF"
      ],
      "metadata": {
        "id": "BzX7wgcDfN7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n"
      ],
      "metadata": {
        "id": "SuaVFNvRfDQ3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "x_tfidf = tfidf.fit_transform(df['clean_review'])"
      ],
      "metadata": {
        "id": "pHkutwioflTk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Additional Textual Feature:**\n",
        "\n",
        "*     Word Count\n",
        "*     Character Count\n",
        "*     Average word length\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WsXZ5pidf2gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_count'] = df['clean_review'].apply(lambda x: len(x.split()))\n",
        "\n",
        "df['char_count'] = df['clean_review'].apply(len)\n",
        "\n",
        "df['avg_word_length'] = df['char_count'] / df['word_count']\n",
        "\n",
        "print(\"Word Count:\")\n",
        "print(df['word_count'].describe())\n",
        "\n",
        "print(\"\\nCharacter Count:\")\n",
        "print(df['char_count'].describe())\n",
        "\n",
        "print(\"\\nAverage Word Length:\")\n",
        "print(df['avg_word_length'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rStUSz6Hf2Cv",
        "outputId": "9030247e-f41f-4c1f-d266-276879d35efb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count:\n",
            "count    50000.000000\n",
            "mean       121.531960\n",
            "std         91.573864\n",
            "min          1.000000\n",
            "25%         65.000000\n",
            "50%         90.000000\n",
            "75%        148.000000\n",
            "max       1440.000000\n",
            "Name: word_count, dtype: float64\n",
            "\n",
            "Character Count:\n",
            "count    50000.000000\n",
            "mean       827.739820\n",
            "std        638.456818\n",
            "min          5.000000\n",
            "25%        433.000000\n",
            "50%        608.000000\n",
            "75%       1008.000000\n",
            "max       9243.000000\n",
            "Name: char_count, dtype: float64\n",
            "\n",
            "Average Word Length:\n",
            "count    50000.000000\n",
            "mean         6.762380\n",
            "std          0.448175\n",
            "min          5.000000\n",
            "25%          6.461538\n",
            "50%          6.746988\n",
            "75%          7.045455\n",
            "max         16.131579\n",
            "Name: avg_word_length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Model Development**"
      ],
      "metadata": {
        "id": "p7ifB_sjiJJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding\n",
        "\n"
      ],
      "metadata": {
        "id": "uVg4KboJiN5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y= le.fit_transform(df['sentiment'])  #0 = negative,1= positive\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jqvSsdpXiZ-n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train - Test Split"
      ],
      "metadata": {
        "id": "iNJTpuSuisRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_tfidf,y,test_size=0.21,random_state=42)"
      ],
      "metadata": {
        "id": "SbjgNPSxiwtm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models to try:**\n",
        "\n",
        "*    Logistic Regression\n",
        "*    Naive Bayes\n",
        "*    Support Vector Machine\n",
        "*    Random Forest\n"
      ],
      "metadata": {
        "id": "PJH5A6bNjES4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression:**"
      ],
      "metadata": {
        "id": "mScepcNRjTur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "lr.fit(x_train,y_train)\n",
        "\n",
        "y_pred_lr = lr.predict(x_test)\n",
        "print(classification_report(y_test,y_pred_lr))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-7LD71T3jTKa",
        "outputId": "68d56fa4-3a19-4749-a84b-f91c1b21fac1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.85      0.86      5201\n",
            "           1       0.86      0.87      0.86      5299\n",
            "\n",
            "    accuracy                           0.86     10500\n",
            "   macro avg       0.86      0.86      0.86     10500\n",
            "weighted avg       0.86      0.86      0.86     10500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes:**"
      ],
      "metadata": {
        "id": "fI7_5Fm3j8bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "\n",
        "nb.fit(x_train,y_train)\n",
        "\n",
        "y_pred_nb = nb.predict(x_test)\n",
        "print(classification_report(y_test,y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yb66TUMWj8MW",
        "outputId": "98599324-e1ad-45cd-9264-0456df561aeb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83      5201\n",
            "           1       0.83      0.84      0.84      5299\n",
            "\n",
            "    accuracy                           0.83     10500\n",
            "   macro avg       0.83      0.83      0.83     10500\n",
            "weighted avg       0.83      0.83      0.83     10500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine:**"
      ],
      "metadata": {
        "id": "zA5OSBHOkd8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "svc = LinearSVC()\n",
        "\n",
        "svc.fit(x_train,y_train)\n",
        "\n",
        "y_pred_svm = svc.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r3JIz4aTkoW3",
        "outputId": "934a0d67-5150-410a-d105-c21b2c1c3444"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86      5201\n",
            "           1       0.86      0.87      0.86      5299\n",
            "\n",
            "    accuracy                           0.86     10500\n",
            "   macro avg       0.86      0.86      0.86     10500\n",
            "weighted avg       0.86      0.86      0.86     10500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest:**"
      ],
      "metadata": {
        "id": "_3D5xguslE2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200)\n",
        "\n",
        "rf.fit(x_train,y_train)\n",
        "\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a0LBmwyGlHff",
        "outputId": "357e8f92-963f-4cb7-af0f-e6f72b78749f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.84      5201\n",
            "           1       0.84      0.84      0.84      5299\n",
            "\n",
            "    accuracy                           0.84     10500\n",
            "   macro avg       0.84      0.84      0.84     10500\n",
            "weighted avg       0.84      0.84      0.84     10500\n",
            "\n"
          ]
        }
      ]
    }
  ]
}